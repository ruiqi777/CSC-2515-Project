{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Classification System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inflect in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kevinzhenshuai\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kevinzhenshuai\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kevinzhenshuai\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (0.6.1.post1)\n",
      "Requirement already satisfied: langdetect in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (1.0.8)\n",
      "Requirement already satisfied: gensim>=3.4.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (3.8.3)\n",
      "Requirement already satisfied: janome in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (0.4.1)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (0.3.2)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (1.2.10)\n",
      "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (4.6.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (0.8.7)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (2020.6.8)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (0.23.1)\n",
      "Requirement already satisfied: torch>=1.1.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (1.7.0)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (0.2.5)\n",
      "Requirement already satisfied: ftfy in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (5.8)\n",
      "Requirement already satisfied: lxml in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (4.5.2)\n",
      "Requirement already satisfied: gdown in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (3.12.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (3.2.2)\n",
      "Requirement already satisfied: segtok>=1.5.7 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (1.5.10)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (0.1.94)\n",
      "Requirement already satisfied: mpld3==0.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (3.5.1)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (1.7.0)\n",
      "Requirement already satisfied: six in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from langdetect->flair) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (1.5.0)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (0.29.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kevinzhenshuai\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (3.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from bpemb>=0.3.2->flair) (2.24.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
      "Requirement already satisfied: overrides==3.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (2.1.0)\n",
      "Requirement already satisfied: future in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from torch>=1.1.0->flair) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from torch>=1.1.0->flair) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from torch>=1.1.0->flair) (0.6)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (1.5.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from gdown->flair) (3.0.12)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->flair) (20.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->flair) (3.14.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->flair) (0.0.43)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->flair) (0.9.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.2)\n",
      "Requirement already satisfied: click in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from sacremoses->transformers>=3.0.0->flair) (7.1.2)\n",
      "Requirement already up-to-date: tensorflow in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kevinzhenshuai\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already up-to-date: keras in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kevinzhenshuai\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.7.0 imblearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kevinzhenshuai\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install inflect\n",
    "!pip install vaderSentiment\n",
    "!pip install textblob\n",
    "!pip install flair\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade keras\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import html\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from flair.embeddings import FlairEmbeddings, BertEmbeddings, WordEmbeddings, DocumentRNNEmbeddings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D, LSTM\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D, MaxPooling2D\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack, csr_matrix, coo_matrix\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from keras.layers import Input, Embedding, Dot, Reshape, Dense,concatenate, Bidirectional,LSTM\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Reading JSON file which contains multiple JSON document\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         200000 non-null  float64\n",
      " 1   reviewTime      200000 non-null  object \n",
      " 2   reviewerID      200000 non-null  object \n",
      " 3   reviewText      199964 non-null  object \n",
      " 4   summary         199965 non-null  object \n",
      " 5   unixReviewTime  200000 non-null  int64  \n",
      " 6   category        200000 non-null  object \n",
      " 7   price           200000 non-null  object \n",
      " 8   itemID          200000 non-null  object \n",
      " 9   reviewHash      200000 non-null  object \n",
      " 10  image           463 non-null     object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 16.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>08 24, 2010</td>\n",
       "      <td>u04428712</td>\n",
       "      <td>So is Katy Perry's new album \"Teenage Dream\" c...</td>\n",
       "      <td>Amazing that I Actually Bought This...More Ama...</td>\n",
       "      <td>1282608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$35.93</td>\n",
       "      <td>p70761125</td>\n",
       "      <td>85559980</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10 31, 2009</td>\n",
       "      <td>u06946603</td>\n",
       "      <td>I got this CD almost 10 years ago, and given t...</td>\n",
       "      <td>Excellent album</td>\n",
       "      <td>1256947200</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>$11.28</td>\n",
       "      <td>p85427891</td>\n",
       "      <td>41699565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 13, 2015</td>\n",
       "      <td>u92735614</td>\n",
       "      <td>I REALLY enjoy this pairing of Anderson and Po...</td>\n",
       "      <td>Love the Music, Hate the Light Show</td>\n",
       "      <td>1444694400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$89.86</td>\n",
       "      <td>p82172532</td>\n",
       "      <td>24751194</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>06 28, 2017</td>\n",
       "      <td>u35112935</td>\n",
       "      <td>Finally got it . It was everything thought it ...</td>\n",
       "      <td>Great</td>\n",
       "      <td>1498608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.89</td>\n",
       "      <td>p15255251</td>\n",
       "      <td>22820631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 12, 2015</td>\n",
       "      <td>u07141505</td>\n",
       "      <td>Look at all star cast.  Outstanding record, pl...</td>\n",
       "      <td>Love these guys.</td>\n",
       "      <td>1444608000</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$15.24</td>\n",
       "      <td>p82618188</td>\n",
       "      <td>53377470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall   reviewTime reviewerID  \\\n",
       "0      4.0  08 24, 2010  u04428712   \n",
       "1      5.0  10 31, 2009  u06946603   \n",
       "2      4.0  10 13, 2015  u92735614   \n",
       "3      5.0  06 28, 2017  u35112935   \n",
       "4      4.0  10 12, 2015  u07141505   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  So is Katy Perry's new album \"Teenage Dream\" c...   \n",
       "1  I got this CD almost 10 years ago, and given t...   \n",
       "2  I REALLY enjoy this pairing of Anderson and Po...   \n",
       "3  Finally got it . It was everything thought it ...   \n",
       "4  Look at all star cast.  Outstanding record, pl...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0  Amazing that I Actually Bought This...More Ama...      1282608000   \n",
       "1                                    Excellent album      1256947200   \n",
       "2                Love the Music, Hate the Light Show      1444694400   \n",
       "3                                              Great      1498608000   \n",
       "4                                   Love these guys.      1444608000   \n",
       "\n",
       "           category   price     itemID reviewHash image  \n",
       "0               Pop  $35.93  p70761125   85559980   NaN  \n",
       "1  Alternative Rock  $11.28  p85427891   41699565   NaN  \n",
       "2               Pop  $89.86  p82172532   24751194   NaN  \n",
       "3               Pop  $11.89  p15255251   22820631   NaN  \n",
       "4              Jazz  $15.24  p82618188   53377470   NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainList = []\n",
    "print(\"Started Reading JSON file which contains multiple JSON document\")\n",
    "with open(\"train.json\", \"r\") as f:\n",
    "    for jsonObj in f:\n",
    "        trainDict = json.loads(jsonObj)\n",
    "        trainList.append(trainDict)\n",
    "        \n",
    "trainDF = pd.DataFrame(data = trainList)\n",
    "trainDF.info()\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoise Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_escaping(text):\n",
    "    '''html escaping: Html character codes (i.e., &...;) are replaced with an ASCII equivalent'''\n",
    "    return html.unescape(text)\n",
    "\n",
    "def to_lower(text):\n",
    "    '''lower case all words in text'''\n",
    "    return text.lower()\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    '''remove urls'''\n",
    "    return re.sub(r\"http\\S+\", ' ', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    '''Remove punctuation from text'''\n",
    "    for char in string.punctuation:\n",
    "        text = text.replace(char,' ')\n",
    "    return text\n",
    "        \n",
    "def denoise_text(text):\n",
    "    text = str(text) # make sure all inputs are type string\n",
    "    text = to_lower(text)\n",
    "    text = strip_html(text)\n",
    "    text = html_escaping(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_punctuation(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and normalize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_extraction(text):    \n",
    "    '''removing stopwords from the sentence and tokenize the sentence'''\n",
    "    stopWords = stopwords.words('english')\n",
    "    # append words with puncutations stripped\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in stopWords]\n",
    "    stopWords.extend(stripped)\n",
    "    # remove duplicates for runtime\n",
    "    stopWords= list(dict.fromkeys(stopWords))\n",
    "    \n",
    "    ignore = stopWords   \n",
    "    words = re.sub(\"[^\\w]\", \" \",  text).split()    \n",
    "    cleaned_words = [w for w in words if w not in ignore]    \n",
    "    return cleaned_words\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def detokenize_text(words):\n",
    "    '''detokenize words into a text string'''\n",
    "    return ' '.join(words)\n",
    "\n",
    "def normalize_text(text):\n",
    "    words = word_extraction(text)\n",
    "    #words = lemmatize_verbs(words)\n",
    "    words = stem_words(words)\n",
    "    text = detokenize_text(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviewer ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(trainDF.reviewerID)\n",
    "encoded_reviewerID = encoder.transform(trainDF.reviewerID)\n",
    "trainDF['userID'] = encoded_reviewerID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unixReviewTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekday(unixTime):\n",
    "    '''Extact Weekday as localeâ€™s abbreviated name from unixReviewTime as the feature'''\n",
    "    return datetime.fromtimestamp(unixTime, timezone.utc).strftime(\"%A\")\n",
    "\n",
    "def get_year(unixTime):\n",
    "    return int(datetime.fromtimestamp(unixTime,timezone.utc).strftime('%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN -------------------------------------------------------\n",
    "trainDF['weekday'] = trainDF['unixReviewTime'].apply(lambda x: get_weekday(x))\n",
    "trainDF['year'] = trainDF['unixReviewTime'].apply(lambda x: get_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuesday      32180\n",
       "Wednesday    29868\n",
       "Monday       29066\n",
       "Thursday     28796\n",
       "Friday       28243\n",
       "Saturday     26427\n",
       "Sunday       25420\n",
       "Name: weekday, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF['weekday'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['price'] = trainDF['price'].str.replace('$', '')\n",
    "trainDF['price'] = trainDF['price'].apply(lambda x : pd.to_numeric(x,errors = 'coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5ZZzLvgMzojy",
    "outputId": "544c33c6-9873-4f42-877b-7d9222aadbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Alldata  NaN Price     ratio\n",
      "Alternative Rock    0.283790   0.357012  1.258015\n",
      "Classical           0.094275   0.082754  0.877789\n",
      "Dance & Electronic  0.062630   0.050165  0.800970\n",
      "Jazz                0.098930   0.072867  0.736552\n",
      "Pop                 0.460375   0.437202  0.949666\n"
     ]
    }
   ],
   "source": [
    "# There are several methods to determine how to handle NaN values \n",
    "#- including dropping them, filling with mode or mean, or replacing with an \"Other\" value\n",
    "# start with data exploration - can check if there a pattern in where the NaN values appear or if the rows with NaN are randomly distributed\n",
    "\n",
    "# For Example - is the a pattern in job categories where NaN contract type appears or is it similar to the full data set?\n",
    "\n",
    "a = trainDF['category'].value_counts(normalize=True)\n",
    "b = trainDF[trainDF['price'].isnull()]['category'].value_counts(normalize=True)\n",
    "print (pd.DataFrame({'Alldata': a, 'NaN Price':b,'ratio':b/a}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hzYYHjEzzoj0"
   },
   "outputs": [],
   "source": [
    "# fill null price with mode\n",
    "trainDF['price'].fillna(trainDF['price'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target variable: category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop                   92075\n",
       "Alternative Rock      56758\n",
       "Jazz                  19786\n",
       "Classical             18855\n",
       "Dance & Electronic    12526\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Alternative Rock      12.235644\n",
       "Classical             18.253591\n",
       "Dance & Electronic    12.780753\n",
       "Jazz                  14.267939\n",
       "Pop                   13.650443\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.groupby('category')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.get_dummies(data=trainDF['category'], columns=['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP on text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:414: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/b003hjwjy6?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#TRAIN -------------------------------------------------------\n",
    "trainDF['reviewText'] = trainDF['reviewText'].apply(lambda x: denoise_text(x)) \n",
    "trainDF['reviewText'] = trainDF['reviewText'].apply(lambda x: normalize_text(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".......\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".........\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"..........\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".....................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"..//..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \". . . .  .  .  .  .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"....................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".....................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#TRAIN -------------------------------------------------------\n",
    "trainDF['summary'] = trainDF['summary'].apply(lambda x: denoise_text(x)) \n",
    "trainDF['summary'] = trainDF['summary'].apply(lambda x: normalize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 262 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#replace null summary with review text, vice versa. Drop null column when both are empty entries\n",
    "trainDF.loc[trainDF.summary =='', 'summary'] = trainDF.reviewText\n",
    "trainDF.loc[trainDF.reviewText =='', 'reviewText'] = trainDF.summary\n",
    "trainDF = trainDF.loc[trainDF.summary !=''].loc[trainDF.reviewText !=''].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-100</td>\n",
       "      <td>156161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-300</td>\n",
       "      <td>37562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300-500</td>\n",
       "      <td>4909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;500</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bins  counts\n",
       "0    0-100  156161\n",
       "1  100-300   37562\n",
       "2  300-500    4909\n",
       "3     >500    1353"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_reviewText =pd.DataFrame({'count':trainDF.reviewText.apply(lambda x : len(x.split()))})\n",
    "\n",
    "words_reviewText['bins'] =pd.cut(words_reviewText['count'], bins=[0,100,300,500,np.inf], labels=['0-100', '100-300', '300-500','>500'])\n",
    "reviewText_distribution = words_reviewText.groupby('bins').size().reset_index().rename(columns={0:'counts'})\n",
    "\n",
    "sns.barplot(x='bins', y='counts', data=reviewText_distribution).set_title(\"Word distribution per bin\")\n",
    "reviewText_distribution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 998 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# since word count more than 500 is less than majority\n",
    "MAX_LENGTH_reivewText = 500\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText train vocabulary size 100817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embed reviewText\n",
    "tokenizer.fit_on_texts(trainDF.reviewText.values)\n",
    "reviewText_train_seq = tokenizer.texts_to_sequences(trainDF.reviewText.values)\n",
    "reviewText_train_padded = pad_sequences(reviewText_train_seq, maxlen=MAX_LENGTH_reivewText)\n",
    "print(\"reviewText train vocabulary size %g\\n\" %(len(tokenizer.word_index) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_reviewText = 103450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-5</td>\n",
       "      <td>179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5-10</td>\n",
       "      <td>18997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-25</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;25</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bins  counts\n",
       "0    0-5  179400\n",
       "1   5-10   18997\n",
       "2  10-25    1123\n",
       "3    >25     465"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfVklEQVR4nO3de7gddX3v8fdHAogXMJCtQkIMSLQFqvEQI603LG1IOSrYAxq0EGs0QrWnHtueSrVC4VBLPZYeasGHlpCAglAQiR4o5EAlSLntYLgqsrnHRIgkQrxATficP+a3YPZm7Z2VsGetvZPP63nm2bO+M79Zv5k82Z89v5k1S7aJiIgYbS/qdQciImLrlICJiIhGJGAiIqIRCZiIiGhEAiYiIhqRgImIiEYkYGKbIelESV/djPUtaZ8y/xVJfzVK/Zgq6WeStiuvvyPpo6Ox7bK9KyTNG63tdctIx2HoMYvxIQETPSPpeEmXD6ndO0xtbnd7N5jtY22fvKn1JD0o6Xc2sa2Hbb/M9sYX2q92oWn792wvfqHbHktG85hF9yRgopeWAW+t/SX/amB74L8Mqe1T1u2YpAmj3NdRMVb71W05E9k2JGCil26hCpQZ5fU7gH8H7hlSu8/2Kkl7SFoiaa2kAUkfa22o/CV/saSvSnoS+LCkvSRdK2m9pKXApJE6I+nPJa2WtErSR4YsWyTpf5X5SZK+LemnpS/XSXqRpPOAqcC3ynDO/5Q0rQy1zZf0MHBNrVYPm9dKulnSE5Iuk7Rrea+DJK0c0pcHJf2OpDnAXwIfKO93W1n+7FBT6dfnJD0k6TFJ50rapSxr9WOepIcl/UTSZ0c4PovKUOHSckyvlfSa2vJfK8vWSrpH0vuHtD1T0uWSfg68a5i3Ge44DDpmZR9PlnR96ctVkkb8943uS8BEz9j+T+AmqhCh/LwO+O6QWuvs5QJgJbAHcATwN5IOrm3yMOBi4BXA14DzgeVUwXIyMOx1ifLL+s+A3wWmAyMNc/1p6Ucf8CqqX/K2fTTwMPCeMpzzd7U27wR+HThkmG0eA3yk7NsG4PQR3h+qN/w34G+AC8v7vbHNah8u07uAvYGXAV8ess7bgNcDBwOfl/TrI7zth6iO5SRgBdVxRtJLgaVUx/yVwFHAGZL2q7X9IHAK8HKqf+N2Nuc4fBD4w/J+O1D9+8UYkoCJXruW58Lk7VQBc92Q2rWS9qT6RfgXtp+yvQL4F+Do2rZusP1N289Q/fJ/M/BXtp+2vQz41gj9eD9wju07bf8cOHGEdX8F7A68xvavbF/nTT/U70TbP7f9y2GWn1d7778C3j9Kw0gfAv7e9v22fwYcD8wdcvb017Z/afs24DagXVC1/F/by2w/DXwW+M3yb/Nu4EHb59jeYPtW4BKqPwRaLrN9ve1nbD81zPY35zicY/uH5ZhexHNnvTFGJGCi15YBb5M0EeizfS/wH8Bvldr+ZZ09gLW219faPgRMrr1+pDa/B7Cu/KKqrz+cPYa0H2ndLwIDwFWS7pf0mRHWbde3TS1/iGrocDSGfPZg8L48BEygOvNq+XFt/hdUZznDebafJbDWlvd4DfCWMmz4U0k/pQq3V7dr28n22fRx2Jx+Rw8kYKLXbgB2ARYA1wPYfhJYVWqrbD9QXu8q6eW1tlOBH9Ve188iVgMTy9BNff3hrAb27GRd2+tt/6ntvYH3AJ+uDdUNdyazqTOcoe/9K+AnwM+Bl7QWlL/m+zZju6uofvnXt70BeHQT7TbZT0kvA3Yt7/EIcK3tV9Sml9k+bjP6Omj7DD4OMQ4lYKKnyvBGP/BpqqGxlu+W2rKy3iNUZzZfkPRiSW8A5lOuAbTZ7kNlu38taQdJb6MKg+FcRHVjwL6SXgKcMNyKkt4taR9JAp4ENpYJql/ce29it9v5g9p7nwRcXG7J/SHwYkn/VdL2wOeAHWvtHgWmSRru//IFwP8oNzy8jOeu2WzYgj4CHCrpbZJ2oLoWc1P5t/k28DpJR0vavkxv3sT1nHaGOw4xDiVgYiy4lupCbf3C73WlVr89+ShgGtVfzJcCJ9heOsJ2Pwi8hWoY5wTg3OFWtH0F8A/ANVTDX9eMsN3pwP8DfkZ1BnaG7e+UZV8APleGiTbnovN5wCKqYZ8XA/+99OsJ4I+orjf9iOqMpn5X2b+Wn49LurXNdheWbS8DHgCeAv54M/o11PlUx3ItcADVMBhl6HI2MJfq3+fHwKkMDsNOtD0OMT4pXzgWEZ2QtAhYaftzve5LjA85g4mIiEYkYCIiohEZIouIiEbkDCYiIhqRB+8VkyZN8rRp03rdjYiIcWX58uU/sd3XblkCppg2bRr9/f297kZExLgiadinXmSILCIiGpGAiYiIRiRgIiKiEQmYiIhoRAImIiIakYCJiIhGJGAiIqIRCZiIiGhEAiYiIhqRT/JvhgP+fNjvq9rmLP/iMb3uQkSMcTmDiYiIRjQWMJIWSnpM0p212oWSVpTpQUkrSn2apF/Wln2l1uYASXdIGpB0evkedCTtWLY3IOkmSdNqbeZJurdM85rax4iIGF6TQ2SLgC9T+x502x9ozUv6EvBEbf37bM9os50zgQXAjcDlwBzgCmA+sM72PpLmUn3/9wck7Ur1neEzAQPLJS2xvW4U9y0iIjahsTMY28uAte2WlbOQ9wMXjLQNSbsDO9u+wdU3o50LHF4WHwYsLvMXAweX7R4CLLW9toTKUqpQioiILurVNZi3A4/avrdW20vS9yRdK+ntpTYZWFlbZ2WptZY9AmB7A9XZ0G71eps2g0haIKlfUv+aNWte6D5FRERNrwLmKAafvawGptp+E/Bp4HxJOwNq07b1Hc/DLRupzeCifZbtmbZn9vW1/b6ciIjYQl0PGEkTgN8HLmzVbD9t+/Eyvxy4D3gd1dnHlFrzKcCqMr8S2LO2zV2ohuSerbdpExERXdKLM5jfAX5g+9mhL0l9krYr83sD04H7ba8G1ks6sFxfOQa4rDRbArTuEDsCuKZcp7kSmC1poqSJwOxSi4iILmrsLjJJFwAHAZMkrQROsH02MJfnX9x/B3CSpA3ARuBY260bBI6juiNtJ6q7x64o9bOB8yQNUJ25zAWwvVbSycAtZb2TatuKiIguaSxgbB81TP3DbWqXAJcMs34/sH+b+lPAkcO0WQgs3IzuRkTEKMsn+SMiohEJmIiIaEQCJiIiGpGAiYiIRiRgIiKiEQmYiIhoRAImIiIakYCJiIhGJGAiIqIRCZiIiGhEAiYiIhqRgImIiEYkYCIiohEJmIiIaEQCJiIiGpGAiYiIRiRgIiKiEQmYiIhoRAImIiIa0VjASFoo6TFJd9ZqJ0r6kaQVZTq0tux4SQOS7pF0SK1+gKQ7yrLTJanUd5R0YanfJGlarc08SfeWaV5T+xgREcNr8gxmETCnTf002zPKdDmApH2BucB+pc0ZkrYr658JLACml6m1zfnAOtv7AKcBp5Zt7QqcALwFmAWcIGni6O9eRESMpLGAsb0MWNvh6ocBX7f9tO0HgAFglqTdgZ1t32DbwLnA4bU2i8v8xcDB5ezmEGCp7bW21wFLaR90ERHRoF5cg/mkpNvLEFrrzGIy8EhtnZWlNrnMD60PamN7A/AEsNsI24qIiC7qdsCcCbwWmAGsBr5U6mqzrkeob2mbQSQtkNQvqX/NmjUj9TsiIjZTVwPG9qO2N9p+BvhnqmskUJ1l7FlbdQqwqtSntKkPaiNpArAL1ZDccNtq15+zbM+0PbOvr++F7FpERAzR1YAp11Ra3ge07jBbAswtd4btRXUx/2bbq4H1kg4s11eOAS6rtWndIXYEcE25TnMlMFvSxDIEN7vUIiKiiyY0tWFJFwAHAZMkraS6s+sgSTOohqweBD4OYPsuSRcBdwMbgE/Y3lg2dRzVHWk7AVeUCeBs4DxJA1RnLnPLttZKOhm4pax3ku1ObzaIiIhR0ljA2D6qTfnsEdY/BTilTb0f2L9N/SngyGG2tRBY2HFnIyJi1OWT/BER0YgETERENCIBExERjUjAREREIxIwERHRiARMREQ0IgETERGNSMBEREQjEjAREdGIBExERDQiARMREY1IwERERCMSMBER0YgETERENCIBExERjUjAREREIxIwERHRiARMREQ0IgETERGNSMBEREQjGgsYSQslPSbpzlrti5J+IOl2SZdKekWpT5P0S0kryvSVWpsDJN0haUDS6ZJU6jtKurDUb5I0rdZmnqR7yzSvqX2MiIjhNXkGswiYM6S2FNjf9huAHwLH15bdZ3tGmY6t1c8EFgDTy9Ta5nxgne19gNOAUwEk7QqcALwFmAWcIGniaO5YRERsWmMBY3sZsHZI7SrbG8rLG4EpI21D0u7AzrZvsG3gXODwsvgwYHGZvxg4uJzdHAIstb3W9jqqUBsadBER0bBeXoP5CHBF7fVekr4n6VpJby+1ycDK2jorS6217BGAElpPALvV623aREREl0zoxZtK+iywAfhaKa0Gptp+XNIBwDcl7QeoTXO3NjPMspHaDO3HAqrhN6ZOndr5DkRExCZ1/QymXHR/N/ChMuyF7adtP17mlwP3Aa+jOvuoD6NNAVaV+ZXAnmWbE4BdqIbknq23aTOI7bNsz7Q9s6+vb3R2MCIigC4HjKQ5wF8A77X9i1q9T9J2ZX5vqov599teDayXdGC5vnIMcFlptgRo3SF2BHBNCawrgdmSJpaL+7NLLSIiuqixITJJFwAHAZMkraS6s+t4YEdgabnb+MZyx9g7gJMkbQA2Asfabt0gcBzVHWk7UV2zaV23ORs4T9IA1ZnLXADbayWdDNxS1juptq2IiOiSxgLG9lFtymcPs+4lwCXDLOsH9m9Tfwo4cpg2C4GFHXc2IiJGXT7JHxERjUjAREREIxIwERHRiARMREQ0IgETERGNSMBEREQjEjAREdGIBExERDQiARMREY1IwERERCMSMBER0YgETERENCIBExERjUjAREREIxIwERHRiARMREQ0IgETERGN6ChgJP2JpJ1VOVvSrZJmN925iIgYvzo9g/mI7SeB2UAf8IfA3zbWq4iIGPc6DRiVn4cC59i+rVaLiIh4nk4DZrmkq6gC5kpJLweeGamBpIWSHpN0Z622q6Slku4tPyfWlh0vaUDSPZIOqdUPkHRHWXa6JJX6jpIuLPWbJE2rtZlX3uNeSfM63MeIiBhFnQbMfOAzwJtt/wLYgWqYbCSLgDlDap8BrrY9Hbi6vEbSvsBcYL/S5gxJ25U2ZwILgOllam1zPrDO9j7AacCpZVu7AicAbwFmASfUgywiIrqj04BZavtW2z8FsP041S/1YdleBqwdUj4MWFzmFwOH1+pft/207QeAAWCWpN2BnW3fYNvAuUPatLZ1MXBwObs5pPR3re11wFKeH3QREdGwCSMtlPRi4CXApHIW0LrusjOwxxa836tsrwawvVrSK0t9MnBjbb2VpfarMj+03mrzSNnWBklPALvV623aDN2/BVRnR0ydOnULdiciIoYzYsAAHwc+RRUmy3kuYJ4E/mkU+9HuhgGPUN/SNoOL9lnAWQAzZ85su05ERGyZEYfIbP8f23sBf2Z7b9t7lemNtr+8Be/3aBn2ovx8rNRXAnvW1psCrCr1KW3qg9pImgDsQjUkN9y2IiKiizq6BmP7HyX9lqQPSjqmNW3B+y0BWnd1zQMuq9XnljvD9qK6mH9zGU5bL+nAcn3lmCFtWts6ArimXKe5EpgtaWIZ1ptdahER0UWbGiIDQNJ5wGuBFcDGUm5ddB+uzQXAQVTXb1ZS3dn1t8BFkuYDDwNHAti+S9JFwN3ABuATtlvvcxzVHWk7AVeUCeBs4DxJA1RnLnPLttZKOhm4pax3ku2hNxtERETDOgoYYCawbzlD6Ijto4ZZdPAw658CnNKm3g/s36b+FCWg2ixbCCzstK8RETH6Or1N+U7g1U12JCIiti6dnsFMAu6WdDPwdKto+72N9CoiIsa9TgPmxCY7ERERW5+OAsb2tU13JCIiti6d3kW2nuc+rLgDsD3wc9s7N9WxiIgY3zo9g3l5/bWkw6keJBkREdHWFn1lsu1vAr89yn2JiIitSKdDZL9fe/kiqs/F5NldERExrE7vIntPbX4D8CDV4/IjIiLa6vQazKa+XCwiImKQjq7BSJoi6dLyFciPSrpE0pRNt4yIiG1Vpxf5z6F6evEeVF/e9a1Si4iIaKvTgOmzfY7tDWVaBPQ12K+IiBjnOg2Yn0j6A0nblekPgMeb7FhERIxvnQbMR4D3Az8GVlN9wVcu/EdExLA6vU35ZGCe7XUAknYF/jdV8ERERDxPp2cwb2iFC1TfGgm8qZkuRUTE1qDTgHlR+X574NkzmE7PfiIiYhvUaUh8CfgPSRdTPSLm/bT5euOIiIiWTj/Jf66kfqoHXAr4fdt3N9qziIgY1zp+mrLtu21/2fY/vpBwkfR6SStq05OSPiXpREk/qtUPrbU5XtKApHskHVKrHyDpjrLsdEkq9R0lXVjqN0matqX9jYiILbNFj+t/IWzfY3uG7RnAAcAvgEvL4tNay2xfDiBpX2AusB8wBzhD0nZl/TOBBcD0Ms0p9fnAOtv7AKcBp3Zh1yIioqbrATPEwcB9th8aYZ3DgK/bftr2A8AAMEvS7sDOtm+wbeBc4PBam8Vl/mLg4NbZTUREdEevA2YucEHt9Scl3S5pYe2utcnAI7V1Vpba5DI/tD6oje0NwBPAbkPfXNICSf2S+tesWTMa+xMREUXPAkbSDsB7gX8tpTOB1wIzqJ4W8KXWqm2ae4T6SG0GF+yzbM+0PbOvL49Wi4gYTb08g/k94FbbjwLYftT2RtvPAP8MzCrrrQT2rLWbAqwq9Slt6oPaSJoA7AKsbWg/IiKijV4GzFHUhsfKNZWW9wF3lvklwNxyZ9heVBfzb7a9Glgv6cByfeUY4LJam3ll/gjgmnKdJiIiuqQnn8aX9BLgd4GP18p/J2kG1VDWg61ltu+SdBFwN9XXNX/C9sbS5jhgEbATcEWZAM4GzpM0QHXmMrfJ/YmIiOfrScDY/gVDLrrbPnqE9U+hzZMDbPcD+7epPwUc+cJ7GhERW6rXd5FFRMRWKgETERGNSMBEREQjEjAREdGIBExERDQiARMREY1IwERERCMSMBER0YgETERENCIBExERjUjAREREIxIwERHRiARMREQ0IgETERGNSMBEREQjEjAREdGIBExERDQiARMREY1IwERERCMSMBER0YieBIykByXdIWmFpP5S21XSUkn3lp8Ta+sfL2lA0j2SDqnVDyjbGZB0uiSV+o6SLiz1myRN6/Y+RkRs63p5BvMu2zNszyyvPwNcbXs6cHV5jaR9gbnAfsAc4AxJ25U2ZwILgOllmlPq84F1tvcBTgNO7cL+REREzVgaIjsMWFzmFwOH1+pft/207QeAAWCWpN2BnW3fYNvAuUPatLZ1MXBw6+wmIiK6o1cBY+AqScslLSi1V9leDVB+vrLUJwOP1NquLLXJZX5ofVAb2xuAJ4DdhnZC0gJJ/ZL616xZMyo7FhERlQk9et+32l4l6ZXAUkk/GGHddmceHqE+UpvBBfss4CyAmTNnPm95RERsuZ6cwdheVX4+BlwKzAIeLcNelJ+PldVXAnvWmk8BVpX6lDb1QW0kTQB2AdY2sS8REdFe1wNG0kslvbw1D8wG7gSWAPPKavOAy8r8EmBuuTNsL6qL+TeXYbT1kg4s11eOGdKmta0jgGvKdZqIiOiSXgyRvQq4tFxznwCcb/vfJN0CXCRpPvAwcCSA7bskXQTcDWwAPmF7Y9nWccAiYCfgijIBnA2cJ2mA6sxlbjd2LCIintP1gLF9P/DGNvXHgYOHaXMKcEqbej+wf5v6U5SAioiI3hhLtylHRMRWJAETERGNSMBEREQjEjAREdGIBExERDQiARMREY1IwERERCMSMBER0YgETERENCIBExERjUjAREREIxIwERHRiARMREQ0IgETERGNSMBEREQjEjAREdGIBExERDQiARMREY1IwERERCMSMBER0YiuB4ykPSX9u6TvS7pL0p+U+omSfiRpRZkOrbU5XtKApHskHVKrHyDpjrLsdEkq9R0lXVjqN0ma1u39jIjY1vXiDGYD8Ke2fx04EPiEpH3LstNszyjT5QBl2VxgP2AOcIak7cr6ZwILgOllmlPq84F1tvcBTgNO7cJ+RURETdcDxvZq27eW+fXA94HJIzQ5DPi67adtPwAMALMk7Q7sbPsG2wbOBQ6vtVlc5i8GDm6d3URERHf09BpMGbp6E3BTKX1S0u2SFkqaWGqTgUdqzVaW2uQyP7Q+qI3tDcATwG5t3n+BpH5J/WvWrBmVfYqIiErPAkbSy4BLgE/ZfpJquOu1wAxgNfCl1qptmnuE+khtBhfss2zPtD2zr69vM/cgIiJG0pOAkbQ9Vbh8zfY3AGw/anuj7WeAfwZmldVXAnvWmk8BVpX6lDb1QW0kTQB2AdY2szcREdFOL+4iE3A28H3bf1+r715b7X3AnWV+CTC33Bm2F9XF/JttrwbWSzqwbPMY4LJam3ll/gjgmnKdJiIiumRCD97zrcDRwB2SVpTaXwJHSZpBNZT1IPBxANt3SboIuJvqDrRP2N5Y2h0HLAJ2Aq4oE1QBdp6kAaozl7kN71NERAzR9YCx/V3aXyO5fIQ2pwCntKn3A/u3qT8FHPkCuhkRES9QPskfERGN6MUQWQQAD5/0G73uwpgw9fN39LoLEY3IGUxERDQiARMREY1IwERERCMSMBER0YgETERENCIBExERjUjAREREIxIwERHRiARMREQ0IgETERGNSMBEREQjEjAREdGIBExERDQiARMREY1IwERERCMSMBER0YgETERENCIBExERjdiqA0bSHEn3SBqQ9Jle9yciYluy1QaMpO2AfwJ+D9gXOErSvr3tVUTEtmNCrzvQoFnAgO37ASR9HTgMuLunvYpowFv/8a297sKYcf0fX/+Ct3HtO945Cj3ZOrxz2bVb3Fa2R7ErY4ekI4A5tj9aXh8NvMX2J2vrLAAWlJevB+7pekc33yTgJ73uxFYkx3N05XiOnvFyLF9ju6/dgq35DEZtaoPS1PZZwFnd6c7okNRve2av+7G1yPEcXTmeo2drOJZb7TUYYCWwZ+31FGBVj/oSEbHN2ZoD5hZguqS9JO0AzAWW9LhPERHbjK12iMz2BkmfBK4EtgMW2r6rx90aDeNqSG8cyPEcXTmeo2fcH8ut9iJ/RET01tY8RBYRET2UgImIiEYkYMaoTh5zI+lBSXdIWiGpv9t9HMs6OTaSFkp6TNKdQ+q7Sloq6d7yc2J3ej12tDs2nR4XSV+U9ANJt0u6VNIrSn2apF+Wf5MVkr7Srf0ZbyR9rfz/v7P8W2xf6gdJeqJ2DD/f676OJAEzBm3mY27eZXvGeL9fviGbOjaLgDlt6p8BrrY9Hbi6vN7WLOL5x6bT47IU2N/2G4AfAsfXlt1X/k1m2D52lPs8bnTwR8vXgF8DfgPYCfhobdl1tWN4UlN9HA0JmLHp2cfc2P5PoPWYmxhFtpcBa9ssOgxYXOYXA4d3rVNjxDDHpqPjYvsq2xvKyxupPoMWg/VLOl/Sb0t63ofCbV/uAriZcXoMEzBj02TgkdrrlaU2lIGrJC0vj72J57yQY/Mq26sBys9XjnrvxqctOS4fAa6ovd5L0vckXSvp7U10cpx4HXA+8Engbkl/KWmPoSuVobGjgX+rlX9T0m2SrpC0X3e6u2W22s/BjHObfMxN8VbbqyS9Elgq6QflL8/Isek5SZ8FNlAN9wCsBqbaflzSAcA3Je1n+8medbJHbG8Evg18W1If8AXgYUm/Zfvm2qpnAMtsX1de30r17K+fSToU+CYwvZt93xw5gxmb2j3m5rHahb1jAWyvKj8fAy6lGloL2h6bdw49fiN4VNLuAOXnY832dtxoe1wknVOO6+WtFSXNA94NfKgM82D7aduPl/nlwH1Uf8lvkyTtUs6ul1Adh/nA7bXlJwB9wKdbNdtP2v5Zmb8c2F7SpK52fDMkYMamdo+5+Ubtwt5XJL1U0ssBJL0UmA3cOcI2txnDHJtb6sdvE5tYAswr8/OAy5rr7bjS9rjY/sNyXA+F6g5I4C+A99r+RauxpL5yAwuS9qb6y/v+LvZ/zJD0Vaqzkb2BY2y/w/Zi20+V5R8FDgGOsv1Mrd2rW9dsJM2i+h3+eNd3oEP5JP8YVU5//4HnHnNzypDle1P9ZQ7VUOf5Q9fZVnV6bCRdABxE9Vj0R4ETbJ8taTfgImAq8DBwpO12NwNstdodG6rhmE0eF0kDwI4894vvRtvHSvpvwElUw2YbqY73txrelTFJ0nuBy2s3QwxdvgF4CFhfSt+wfZKqx18dR3UMfwl82vZ/dKPPWyIBExERjcgQWURENCIBExERjUjAREREIxIwERHRiARMREQ0IgET0UPlCcPP+/ySpH8Z4QGnEeNCHhUTMQbZ/uim14oY23IGE9F7EyQtLt+fcrGkl0j6jqSZAJJ+JumU8oDDGyW9qtSPLN8XcpukPGctxpwETETvvR44q3x/ypPAHw1Z/lKqT8O/EVgGfKzUPw8cUurv7VZnIzqVgInovUdsX1/mvwq8bcjy/6R68i7AcmBamb8eWCTpY1SPFIoYUxIwEb039HlNQ1//ys8902kj5dpp+UbIz1E9eXtFeYZaxJiRgInovamSfrPMHwV8t5NGkl5r+ybbnwd+wuCveIjouQRMRO99H5gn6XZgV+DMDtt9UdId5TbnZcBtTXUwYkvkacoREdGInMFEREQjEjAREdGIBExERDQiARMREY1IwERERCMSMBER0YgETERENOL/A6WSahWDs+VsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_summary =pd.DataFrame({'count':trainDF.summary.apply(lambda x : len(x.split()))})\n",
    "\n",
    "words_summary['bins'] =pd.cut(words_summary['count'], bins=[0,5,10,25,np.inf], labels=['0-5', '5-10', '10-25','>25'])\n",
    "summary_distribution = words_summary.groupby('bins').size().reset_index().rename(columns={0:'counts'})\n",
    "\n",
    "sns.barplot(x='bins', y='counts', data=summary_distribution).set_title(\"Word distribution per bin\")\n",
    "summary_distribution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since word count more than 800 is less than 500.\n",
    "MAX_LENGTH_summary = 25\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary train vocabulary size 21501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embed summary\n",
    "tokenizer.fit_on_texts(trainDF.summary.values)\n",
    "summary_train_seq = tokenizer.texts_to_sequences(trainDF.summary.values)\n",
    "summary_train_padded = pad_sequences(summary_train_seq, maxlen=MAX_LENGTH_summary)\n",
    "print(\"summary train vocabulary size %g\\n\" %(len(tokenizer.word_index) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_summary = 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding col names of review text and summary\n",
    "review_emb_schema = []\n",
    "for i in range(1,reviewText_train_padded.shape[1]+1):\n",
    "    review_emb_schema.append('review_emb_'+str(i))\n",
    "\n",
    "summary_emb_schema = []\n",
    "for i in range(1,summary_train_padded.shape[1]+1):\n",
    "    summary_emb_schema.append('summary_emb_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextDF = pd.DataFrame(reviewText_train_padded, columns = review_emb_schema)\n",
    "summaryDF = pd.DataFrame(summary_train_padded, columns = summary_emb_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([reviewTextDF, summaryDF,trainDF['userID']],axis = 1)\n",
    "y = trainDF['category'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Alternative Rock',\n",
       " 1: 'Classical',\n",
       " 2: 'Dance & Electronic',\n",
       " 3: 'Jazz',\n",
       " 4: 'Pop'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_y = dict(enumerate(trainDF['category'].astype('category').cat.categories))\n",
    "dict_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Split Training Data into Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:635: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.9 \"\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# smote = SMOTE('minority')\n",
    "# X_sm,y_sm = smote.fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_enc = pd.concat([pd.DataFrame(y_sm, columns=['category']),pd.get_dummies(data = y_sm, columns = 'category')],axis = 1)\n",
    "y_enc = pd.concat([pd.DataFrame(y, columns=['category']),pd.get_dummies(data = y, columns = 'category')],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(279525, 526) (199985, 526)\n",
      "(279525,) (199985,)\n"
     ]
    }
   ],
   "source": [
    "print(X_sm.shape, X.shape)\n",
    "print(y_sm.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "h9dcmNbmzokU"
   },
   "outputs": [],
   "source": [
    "# RRP_x_train, RRP_x_val, RRP_y_train, RRP_y_val = train_test_split(X_sm, y_enc , random_state=42, test_size=0.3)\n",
    "RRP_x_train, RRP_x_val, RRP_y_train, RRP_y_val = train_test_split(X, y_enc , random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(MAX_LENGTH_reivewText,MAX_LENGTH_summary):\n",
    "    review_inputs = Input(shape=(MAX_LENGTH_reivewText, ),name = 'review_input')\n",
    "    review_emb = Embedding(vocab_reviewText,\n",
    "                                32,\n",
    "                                input_length=MAX_LENGTH_reivewText,\n",
    "                                name = 'review_emb')(review_inputs)\n",
    "    review_out = Flatten()(review_emb)\n",
    "\n",
    "    summary_inputs = Input(shape=(MAX_LENGTH_summary, ),name = 'summary_inputs')\n",
    "    summary_emb = Embedding(vocab_summary,\n",
    "                                32,\n",
    "                                input_length=MAX_LENGTH_summary,\n",
    "                                name = 'summary_emb')(summary_inputs)\n",
    "    summary_out = Flatten()(summary_emb)\n",
    "    # dot = Dot(name = 'dot', normalize = True, axes = 2)([review_emb,summary_emb])\n",
    "    # merged = Flatten()(dot)\n",
    "    # merged = Reshape(target_shape = [-1,625])(merged)\n",
    "    merged = concatenate([review_out, summary_out])\n",
    "\n",
    "    x = Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001))(user_vec)\n",
    "    x = Dropout(0.1)(x)\n",
    "    predictions = Dense(5, activation='softmax')(x)\n",
    "    model = Model(inputs=[review_inputs,summary_inputs], outputs=predictions)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_73\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "review_input (InputLayer)       [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "summary_inputs (InputLayer)     [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "review_emb (Embedding)          (None, 500, 32)      3310400     review_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "summary_emb (Embedding)         (None, 25, 32)       704000      summary_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 16000)        0           review_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 800)          0           summary_emb[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16800)        0           flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 32)           537632      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 5)            165         dense_48[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,552,197\n",
      "Trainable params: 4,552,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.8400 - acc: 0.6864WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 170s 39ms/step - loss: 0.8400 - acc: 0.6864\n",
      "Epoch 2/5\n",
      "4374/4375 [============================>.] - ETA: 0s - loss: 0.5701 - acc: 0.7926WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 171s 39ms/step - loss: 0.5701 - acc: 0.7926\n",
      "Epoch 3/5\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.3990 - acc: 0.8580WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 170s 39ms/step - loss: 0.3990 - acc: 0.8580\n",
      "Epoch 4/5\n",
      "4374/4375 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.8938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 169s 39ms/step - loss: 0.3025 - acc: 0.8938\n",
      "Epoch 5/5\n",
      "4374/4375 [============================>.] - ETA: 0s - loss: 0.2558 - acc: 0.9112WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 171s 39ms/step - loss: 0.2558 - acc: 0.9111\n"
     ]
    }
   ],
   "source": [
    "model = embedding_model(MAX_LENGTH_reivewText,MAX_LENGTH_summary)\n",
    "filepath=\"weights-simple.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "history = model.fit([RRP_x_train[review_emb_schema],RRP_x_train[summary_emb_schema]], batch_size=32, y=RRP_y_train.drop('category',axis = 1), verbose=1, \n",
    "          shuffle=True, epochs=5, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify mse with best model on validation set\n",
    "prob_textModel = model.predict([RRP_x_val[review_emb_schema],RRP_x_val[summary_emb_schema]])\n",
    "predicted_textModel = np.argmax(prob_textModel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987465831055404"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1 = accuracy_score(RRP_y_val['category'], predicted_textModel)\n",
    "acc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier based on Reviewer ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29286    332\n",
       "61258    317\n",
       "26681    244\n",
       "37512    216\n",
       "4714     192\n",
       "        ... \n",
       "64162      1\n",
       "58017      1\n",
       "60064      1\n",
       "70303      1\n",
       "2047       1\n",
       "Name: userID, Length: 60882, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RRP_x_train.userID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120269</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85018</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169705</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173203</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12292</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139989 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  0  1  2  3  4\n",
       "120269         4  0  0  0  0  1\n",
       "85018          3  0  0  0  1  0\n",
       "169705         0  1  0  0  0  0\n",
       "173203         4  0  0  0  0  1\n",
       "12292          4  0  0  0  0  1\n",
       "...          ... .. .. .. .. ..\n",
       "119879         1  0  1  0  0  0\n",
       "103694         0  1  0  0  0  0\n",
       "131932         4  0  0  0  0  1\n",
       "146867         4  0  0  0  0  1\n",
       "121958         4  0  0  0  0  1\n",
       "\n",
       "[139989 rows x 6 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RRP_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "user_id (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "user_emb (Embedding)         (None, 1, 32)             2313216   \n",
      "_________________________________________________________________\n",
      "FlattenUser (Flatten)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 2,314,437\n",
      "Trainable params: 2,314,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "4374/4375 [============================>.] - ETA: 0s - loss: 1.1486 - acc: 0.5584WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 84s 19ms/step - loss: 1.1486 - acc: 0.5584\n",
      "Epoch 2/10\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 0.7016 - acc: 0.7572WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 83s 19ms/step - loss: 0.7016 - acc: 0.7572\n",
      "Epoch 3/10\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 0.5364 - acc: 0.7811WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 89s 20ms/step - loss: 0.5364 - acc: 0.7810\n",
      "Epoch 4/10\n",
      "4374/4375 [============================>.] - ETA: 0s - loss: 0.4690 - acc: 0.7881WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 90s 21ms/step - loss: 0.4690 - acc: 0.7880\n",
      "Epoch 5/10\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.4360 - acc: 0.7935WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 91s 21ms/step - loss: 0.4360 - acc: 0.7935\n",
      "Epoch 6/10\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 0.4184 - acc: 0.7984WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 93s 21ms/step - loss: 0.4184 - acc: 0.7984\n",
      "Epoch 7/10\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 0.4084 - acc: 0.8002WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 97s 22ms/step - loss: 0.4084 - acc: 0.8002\n",
      "Epoch 8/10\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.4007 - acc: 0.8021- ETA: 1s WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 95s 22ms/step - loss: 0.4007 - acc: 0.8021\n",
      "Epoch 9/10\n",
      "4374/4375 [============================>.] - ETA: 0s - loss: 0.3967 - acc: 0.8034WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 96s 22ms/step - loss: 0.3967 - acc: 0.8034\n",
      "Epoch 10/10\n",
      "4373/4375 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8044WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "4375/4375 [==============================] - 93s 21ms/step - loss: 0.3922 - acc: 0.8043\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 32 \n",
    "NUM_USERS = trainDF['userID'].nunique()+5\n",
    "ROW_COUNT = RRP_x_train.shape[0]\n",
    "\n",
    "def EmbeddingRec(EMBEDDING_SIZE, NUM_USERS, ROW_COUNT):\n",
    "    user_input = Input(shape=(1,), name='user_id')\n",
    "\n",
    "    user_emb = Embedding(output_dim=EMBEDDING_SIZE, input_dim=NUM_USERS, input_length=ROW_COUNT, name='user_emb')(user_input)\n",
    "    user_vec = Flatten(name='FlattenUser')(user_emb)\n",
    "\n",
    "    user_model = Model(inputs=user_input, outputs=user_vec)\n",
    "\n",
    "    x = Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001))(user_vec)\n",
    "    x = Dropout(0.1)(x)\n",
    "    predictions = Dense(5, activation='softmax')(x)\n",
    "    model = Model(inputs=user_input, outputs=predictions)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    model.summary()\n",
    "    return model, user_model\n",
    "\n",
    "reviewID_model,user_model = EmbeddingRec(EMBEDDING_SIZE, NUM_USERS,ROW_COUNT)\n",
    "filepath=\"userID_embeddingModel.hdf5\"\n",
    "\n",
    "callbacks = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "# fit network\n",
    "history = reviewID_model.fit(RRP_x_train['userID'], y=RRP_y_train.drop('category',axis=1), epochs =10,\n",
    "                            verbose = 1, \n",
    "                            callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify mse with best model on validation set\n",
    "prob_userModel = reviewID_model.predict(RRP_x_val['userID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_userModel = np.argmax(prob_userModel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5922394826321755"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2 = accuracy_score(RRP_y_val['category'], predicted_userModel)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = acc1/(acc1+acc2)\n",
    "w2 = 1- w1\n",
    "prob = w1*prob_textModel + w2*prob_userModel\n",
    "predicted = np.argmax(prob,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7250983398893259"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(RRP_y_val['category'], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All potentially related embeddings concatenated in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 32\n",
    "NUM_USERS = trainDF['reviewerID'].nunique()+5\n",
    "ROW_COUNT = RRP_x_train.shape[0]\n",
    "\n",
    "def embeddingAll(MAX_LENGTH_reivewText,MAX_LENGTH_summary, EMBEDDING_SIZE, NUM_USERS, ROW_COUNT):\n",
    "    review_inputs = Input(shape=(MAX_LENGTH_reivewText, ),name = 'review_input')\n",
    "    review_emb = Embedding(vocab_reviewText,\n",
    "                                32,\n",
    "                                input_length=MAX_LENGTH_reivewText,\n",
    "                                name = 'review_emb')(review_inputs)\n",
    "    review_out = Flatten()(review_emb)\n",
    "\n",
    "    summary_inputs = Input(shape=(MAX_LENGTH_summary, ),name = 'summary_inputs')\n",
    "    summary_emb = Embedding(vocab_summary,\n",
    "                                32,\n",
    "                                input_length=MAX_LENGTH_summary,\n",
    "                                name = 'summary_emb')(summary_inputs)\n",
    "    summary_out = Flatten()(summary_emb)\n",
    "    \n",
    "    user_input = Input(shape=(1,), name='user_id')\n",
    "\n",
    "    user_emb = Embedding(output_dim=EMBEDDING_SIZE, input_dim=NUM_USERS, input_length=ROW_COUNT, name='user_emb')(user_input)\n",
    "    user_out = Flatten(name='FlattenUser')(user_emb)\n",
    "    \n",
    "    # dot = Dot(name = 'dot', normalize = True, axes = 2)([review_emb,summary_emb])\n",
    "    # merged = Flatten()(dot)\n",
    "    # merged = Reshape(target_shape = [-1,625])(merged)\n",
    "    merged = concatenate([review_out, summary_out, user_out])\n",
    "\n",
    "    x = Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001))(user_vec)\n",
    "    x = Dropout(0.1)(x)\n",
    "    predictions = Dense(5, activation='softmax')(x)\n",
    "    model = Model(inputs=[review_inputs,summary_inputs,user_input], outputs=predictions)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_75\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "review_input (InputLayer)       [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "summary_inputs (InputLayer)     [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "review_emb (Embedding)          (None, 500, 32)      3310400     review_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "summary_emb (Embedding)         (None, 25, 32)       704000      summary_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "user_emb (Embedding)            (None, 1, 32)        2313216     user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 16000)        0           review_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 800)          0           summary_emb[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUser (Flatten)           (None, 32)           0           user_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16832)        0           flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "                                                                 FlattenUser[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 32)           538656      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 5)            165         dense_50[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,866,437\n",
      "Trainable params: 6,866,437\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.8340 - acc: 0.6835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "4375/4375 [==============================] - 243s 55ms/step - loss: 0.8340 - acc: 0.6835\n",
      "Epoch 2/5\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.4092 - acc: 0.8561WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "4375/4375 [==============================] - 242s 55ms/step - loss: 0.4092 - acc: 0.8561\n",
      "Epoch 3/5\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.1968 - acc: 0.9298WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "4375/4375 [==============================] - 246s 56ms/step - loss: 0.1968 - acc: 0.9298\n",
      "Epoch 4/5\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.1156 - acc: 0.9559WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "4375/4375 [==============================] - 244s 56ms/step - loss: 0.1156 - acc: 0.9559\n",
      "Epoch 5/5\n",
      "4375/4375 [==============================] - ETA: 0s - loss: 0.0846 - acc: 0.9662WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "4375/4375 [==============================] - 244s 56ms/step - loss: 0.0846 - acc: 0.9662\n"
     ]
    }
   ],
   "source": [
    "model_embed = embeddingAll(MAX_LENGTH_reivewText,MAX_LENGTH_summary, EMBEDDING_SIZE, NUM_USERS, ROW_COUNT)\n",
    "filepath=\"model_embed.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history = model_embed.fit([RRP_x_train[review_emb_schema],RRP_x_train[summary_emb_schema],RRP_x_train['userID']], batch_size=32, y=RRP_y_train.drop('category',axis = 1),  verbose=1, \n",
    "          shuffle=True, epochs=5, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify mse with best model on validation set\n",
    "prob_embedModel = model.predict([RRP_x_val[review_emb_schema],RRP_x_val[summary_emb_schema],RRP_x_val['userID']])\n",
    "prob_embedModel = np.argmax(prob_embedModel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987465831055404"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(RRP_y_val['category'], prob_embedModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
